
model:
  dim: 1024
  depth: 6
  heads: 16
  dim_head: 64
  temperature: 18.0
  shared_kv: true
  shared_temperture: false
  checkpoint_every_n: 0
  fused_mlp_checkpoint_lvl: 0
  

optimizer:
  name: 'madgrad'
  args:
    lr: 3.8e-4

scheduler:
  warmup_steps: 2000

text_chunking:
  size: 512

wandb:
  use: true
  project_name: "spotify_language_models"
  id: "" # leave empty if not resuming a previous run

checkpointing:
  dir: '/exp/exp4/acp21rjf/checkpoints/language_modelling_spotipile/3p8e4_512_1536'
  save_every_n_steps: 750
  
training:
  batch_size: 10
  backprop_every: 1
  max_seq_len: 1536 # max cache length

# size: 2048 = batch size 176
# size: 4096 = batch size 88
# size: 8192 = batch size 44
# size: 16384 = batch size 22
# size: 65536 = batch size 5 
# size: 131072 = batch size 2
# size: 360000 (1 hour) =  batch size 1
